{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1NrAM8jhhbxoaJwP05R7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/myTorch/blob/main/04_tensor_indexing_and_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Goal\n",
        "\n",
        "Provide a clear, example-driven reference for selecting, slicing, and filtering data from PyTorch tensors.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Level 1 completed.\n",
        "Basic understanding of tensor shapes and dimensions.\n",
        "\n",
        "## After This Notebook You Can\n",
        "\n",
        "Index and slice tensors confidently.\n",
        "Use boolean masks for selection.\n",
        "Select elements conditionally.\n",
        "Explain indexing methods in interviews.\n",
        "\n",
        "## Out of Scope\n",
        "\n",
        "Advanced autograd behavior.\n",
        "Sparse tensors.\n",
        "Performance optimization.\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS COVERED (SUMMARY)\n",
        "\n",
        "Indexing and selection:\n",
        "\n",
        "* Basic indexing\n",
        "* Slicing\n",
        "* Boolean masking\n",
        "* torch.where\n",
        "* torch.gather\n",
        "* torch.nonzero\n",
        "\n",
        "---\n",
        "\n",
        "## Basic Indexing\n",
        "\n",
        "What it does:\n",
        "Selects elements using integer indices.\n",
        "\n",
        "When to use:\n",
        "Accessing specific elements or rows.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
        "x[0]\n",
        "x[1, 2]\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Forgetting that indexing reduces dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "## Slicing\n",
        "\n",
        "What it does:\n",
        "Selects ranges of elements along dimensions.\n",
        "\n",
        "When to use:\n",
        "Extracting sub-tensors.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x[:, :2]\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Assuming slicing copies data (it often shares memory).\n",
        "\n",
        "---\n",
        "\n",
        "## Boolean Masking\n",
        "\n",
        "What it does:\n",
        "Selects elements where a condition is true.\n",
        "\n",
        "When to use:\n",
        "Filtering data based on conditions.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1, 5, 3, 8])\n",
        "mask = x > 3\n",
        "x[mask]\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Mask shape not matching tensor shape.\n",
        "\n",
        "---\n",
        "\n",
        "## torch.where\n",
        "\n",
        "What it does:\n",
        "Selects elements based on a condition.\n",
        "\n",
        "When to use:\n",
        "Conditional replacement or selection.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1, 5, 3, 8])\n",
        "torch.where(x > 3, x, torch.tensor(0))\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* condition\n",
        "* x\n",
        "* y\n",
        "\n",
        "Common mistake:\n",
        "Forgetting x and y must be broadcastable.\n",
        "\n",
        "---\n",
        "\n",
        "## torch.gather\n",
        "\n",
        "What it does:\n",
        "Gathers values along an axis using indices.\n",
        "\n",
        "When to use:\n",
        "Selecting elements using index tensors.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
        "idx = torch.tensor([[2, 1], [0, 2]])\n",
        "torch.gather(x, 1, idx)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* input\n",
        "* dim\n",
        "* index\n",
        "\n",
        "Common mistake:\n",
        "Misunderstanding index shape requirements.\n",
        "\n",
        "---\n",
        "\n",
        "## torch.nonzero\n",
        "\n",
        "What it does:\n",
        "Returns indices of non-zero elements.\n",
        "\n",
        "When to use:\n",
        "Finding positions of valid entries.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([0, 1, 0, 3])\n",
        "torch.nonzero(x)\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Assuming it returns values instead of indices.\n",
        "\n",
        "---\n",
        "\n",
        "## HANDS-ON PRACTICE\n",
        "\n",
        "1. Slice a 2D tensor to extract specific columns.\n",
        "2. Use boolean masking to filter values greater than a threshold.\n",
        "3. Use torch.where to replace negative values with zero.\n",
        "4. Use gather to select elements using an index tensor.\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS RECAP (ONE PLACE)\n",
        "\n",
        "Basic indexing, slicing, boolean masking, where, gather, nonzero\n",
        "\n",
        "---\n",
        "\n",
        "## ONE-SENTENCE SUMMARY\n",
        "\n",
        "Indexing methods select data, they do not change tensor values.\n",
        "\n",
        "---\n",
        "\n",
        "## WHERE THIS FITS NEXT\n",
        "\n",
        "Next reference notebook:\n",
        "PyTorch_Methods_05 â€” Tensor Memory & Copy Methods\n"
      ],
      "metadata": {
        "id": "-n2-qx9YznPX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11d6ea0",
        "outputId": "1e994f97-e712-4008-f2a3-9b3f5c4bd5e9"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"---> Basic Indexing <---\")\n",
        "x = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
        "print(\"Original tensor x:\\n\", x)\n",
        "print(\"x[0]:\", x[0])\n",
        "print(\"x[1, 2]:\", x[1, 2])\n",
        "\n",
        "print(\"\\n---> Slicing <---\")\n",
        "print(\"Original tensor x:\\n\", x)\n",
        "print(\"x[:, :2]:\\n\", x[:, :2])\n",
        "\n",
        "print(\"\\n---> Boolean Masking <---\")\n",
        "x_mask = torch.tensor([1, 5, 3, 8])\n",
        "print(\"Original tensor x_mask:\\n\", x_mask)\n",
        "mask = x_mask > 3\n",
        "print(\"Mask (x_mask > 3):\", mask)\n",
        "print(\"x_mask[mask]:\", x_mask[mask])\n",
        "\n",
        "print(\"\\n---> torch.where <---\")\n",
        "x_where = torch.tensor([1, 5, 3, 8])\n",
        "print(\"Original tensor x_where:\\n\", x_where)\n",
        "print(\"torch.where(x_where > 3, x_where, torch.tensor(0)):\\n\", torch.where(x_where > 3, x_where, torch.tensor(0)))\n",
        "\n",
        "print(\"\\n---> torch.gather <---\")\n",
        "x_gather = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
        "idx_gather = torch.tensor([[2, 1], [0, 2]])\n",
        "print(\"Original tensor x_gather:\\n\", x_gather)\n",
        "print(\"Index tensor idx_gather:\\n\", idx_gather)\n",
        "print(\"torch.gather(x_gather, 1, idx_gather):\\n\", torch.gather(x_gather, 1, idx_gather))\n",
        "\n",
        "print(\"\\n---> torch.nonzero <---\")\n",
        "x_nonzero = torch.tensor([0, 1, 0, 3])\n",
        "print(\"Original tensor x_nonzero:\\n\", x_nonzero)\n",
        "print(\"torch.nonzero(x_nonzero):\\n\", torch.nonzero(x_nonzero))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> Basic Indexing <---\n",
            "Original tensor x:\n",
            " tensor([[10, 20, 30],\n",
            "        [40, 50, 60]])\n",
            "x[0]: tensor([10, 20, 30])\n",
            "x[1, 2]: tensor(60)\n",
            "\n",
            "---> Slicing <---\n",
            "Original tensor x:\n",
            " tensor([[10, 20, 30],\n",
            "        [40, 50, 60]])\n",
            "x[:, :2]:\n",
            " tensor([[10, 20],\n",
            "        [40, 50]])\n",
            "\n",
            "---> Boolean Masking <---\n",
            "Original tensor x_mask:\n",
            " tensor([1, 5, 3, 8])\n",
            "Mask (x_mask > 3): tensor([False,  True, False,  True])\n",
            "x_mask[mask]: tensor([5, 8])\n",
            "\n",
            "---> torch.where <---\n",
            "Original tensor x_where:\n",
            " tensor([1, 5, 3, 8])\n",
            "torch.where(x_where > 3, x_where, torch.tensor(0)):\n",
            " tensor([0, 5, 0, 8])\n",
            "\n",
            "---> torch.gather <---\n",
            "Original tensor x_gather:\n",
            " tensor([[10, 20, 30],\n",
            "        [40, 50, 60]])\n",
            "Index tensor idx_gather:\n",
            " tensor([[2, 1],\n",
            "        [0, 2]])\n",
            "torch.gather(x_gather, 1, idx_gather):\n",
            " tensor([[30, 20],\n",
            "        [40, 60]])\n",
            "\n",
            "---> torch.nonzero <---\n",
            "Original tensor x_nonzero:\n",
            " tensor([0, 1, 0, 3])\n",
            "torch.nonzero(x_nonzero):\n",
            " tensor([[1],\n",
            "        [3]])\n"
          ]
        }
      ]
    }
  ]
}