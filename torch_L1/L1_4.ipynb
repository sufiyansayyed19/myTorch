{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMk8oAcyoJ+ZUF/QwxPBDVQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/myTorch/blob/main/L1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Goal\n",
        "\n",
        "Build an intuitive and practical understanding of tensor dimensionality from 0D to 5D and map each case to real-world data.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Understanding what a tensor is.\n",
        "Basic idea of rank and shape.\n",
        "\n",
        "## After This Notebook You Can\n",
        "\n",
        "Identify whether a tensor is 0D, 1D, 2D, 3D, 4D, or 5D.\n",
        "Map tensor dimensions to real-world meanings.\n",
        "Read tensor shapes and explain what each axis represents.\n",
        "Avoid common dimensionality mistakes in interviews and practice.\n",
        "\n",
        "## Out of Scope\n",
        "\n",
        "Broadcasting rules.\n",
        "Tensor operations and reshaping.\n",
        "PyTorch autograd and gradients.\n",
        "Model architectures.\n",
        "\n",
        "---\n",
        "\n",
        "## 1 THE CONFUSION (WHY THIS EXISTS)\n",
        "\n",
        "Learners often:\n",
        "\n",
        "* Memorize shapes without understanding them\n",
        "* Panic when they see high-dimensional tensors\n",
        "* Confuse data meaning with tensor rank\n",
        "* Forget which dimension represents what\n",
        "\n",
        "Common wrong assumptions:\n",
        "\n",
        "* Higher dimension means more complexity\n",
        "* 4D or 5D tensors are special or advanced\n",
        "* Dimensions are arbitrary\n",
        "\n",
        "This notebook exists to make dimensionality feel normal and predictable.\n",
        "\n",
        "---\n",
        "\n",
        "## 2 CORE MENTAL MODEL (THE IDEA)\n",
        "\n",
        "Key idea:\n",
        "\n",
        "Tensor dimensionality does NOT represent complexity.\n",
        "\n",
        "It represents how many independent axes of variation exist.\n",
        "\n",
        "Each dimension answers one question:\n",
        "\n",
        "* Along what axis do values change?\n",
        "\n",
        "Rules to remember:\n",
        "\n",
        "* Add a dimension when you group things\n",
        "* Remove a dimension when grouping disappears\n",
        "* Dimensions describe structure, not intelligence\n",
        "\n",
        "High-dimensional tensors are common because real-world data is structured.\n",
        "\n",
        "---\n",
        "\n",
        "## 3 MINIMAL PROOF (JUST ENOUGH CODE)\n",
        "\n",
        "Below are minimal, runnable examples illustrating 0D to 5D tensors.\n",
        "\n",
        "### 0D Tensor (Scalar)\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "loss = torch.tensor(0.42)\n",
        "loss\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* Single value\n",
        "* No axes\n",
        "* Commonly represents loss or a single measurement\n",
        "\n",
        "---\n",
        "\n",
        "### 1D Tensor (Vector)\n",
        "\n",
        "```python\n",
        "features = torch.tensor([65, 170, 1])\n",
        "features\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* One axis\n",
        "* Multiple related values\n",
        "* Commonly represents feature vectors or embeddings\n",
        "\n",
        "---\n",
        "\n",
        "### 2D Tensor (Matrix)\n",
        "\n",
        "```python\n",
        "data = torch.tensor([\n",
        "    [65, 170, 1],\n",
        "    [72, 180, 0]\n",
        "])\n",
        "data\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* Two axes\n",
        "* Rows represent samples\n",
        "* Columns represent features\n",
        "\n",
        "---\n",
        "\n",
        "### 3D Tensor\n",
        "\n",
        "```python\n",
        "sequence = torch.randn(5, 10, 8)\n",
        "sequence.shape\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* Three axes\n",
        "* Example meaning: (batch, time, features)\n",
        "* Common in text, audio, and time-series data\n",
        "\n",
        "---\n",
        "\n",
        "### 4D Tensor\n",
        "\n",
        "```python\n",
        "images = torch.randn(4, 3, 32, 32)\n",
        "images.shape\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* Four axes\n",
        "* (batch, channels, height, width)\n",
        "* Standard image representation in deep learning\n",
        "\n",
        "---\n",
        "\n",
        "### 5D Tensor\n",
        "\n",
        "```python\n",
        "videos = torch.randn(2, 10, 3, 32, 32)\n",
        "videos.shape\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* Five axes\n",
        "* (batch, time, channels, height, width)\n",
        "* Used for video or volumetric data\n",
        "\n",
        "---\n",
        "\n",
        "Key observation:\n",
        "\n",
        "Higher dimension does not mean harder math.\n",
        "It only means more structured grouping.\n",
        "\n",
        "---\n",
        "\n",
        "## 4 WHAT CAN GO WRONG (FAILURE MODES)\n",
        "\n",
        "Common mistakes:\n",
        "\n",
        "* Forgetting the batch dimension\n",
        "* Swapping axis meanings\n",
        "* Assuming fixed dimension order without checking\n",
        "* Treating shape as a magic number\n",
        "\n",
        "These mistakes cause silent bugs and model failures.\n",
        "\n",
        "---\n",
        "\n",
        "## 5 INTERVIEW VIEW (VERY IMPORTANT)\n",
        "\n",
        "One-paragraph definition:\n",
        "\n",
        "Tensor dimensionality describes how many independent axes of variation exist in the data and what each axis represents in the real world.\n",
        "\n",
        "Crisp explanations:\n",
        "\n",
        "* 0D represents a single value\n",
        "* 1D represents a list of related values\n",
        "* Higher dimensions represent structured grouping\n",
        "\n",
        "Common interview questions:\n",
        "\n",
        "1. What does a 4D tensor represent in image processing?\n",
        "2. Why do we need a batch dimension?\n",
        "3. What is the difference between 3D and 4D tensors?\n",
        "\n",
        "---\n",
        "\n",
        "## 6 ONE-SENTENCE SUMMARY (CLOSURE)\n",
        "\n",
        "Tensor dimensionality represents structure, not complexity.\n",
        "\n",
        "---\n",
        "\n",
        "## 7 WHERE THIS FITS NEXT (CONTINUITY)\n",
        "\n",
        "This prepares you to reason about tensor creation and properties.\n",
        "\n",
        "Next notebook:\n",
        "Level 1 â€” Creating Tensors and Tensor Properties\n"
      ],
      "metadata": {
        "id": "FqiK1DBTWPbP"
      }
    }
  ]
}