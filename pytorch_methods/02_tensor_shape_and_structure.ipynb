{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdKtHbkft4g2g+11V0Jwfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/myTorch/blob/main/02_tensor_shape_and_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Goal\n",
        "\n",
        "Provide a single, practical reference for PyTorch tensor shape and structure methods so you can change tensor layout safely and intentionally.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Level 1 completed (tensors, memory, reshaping concepts).\n",
        "Ability to run Python code in Google Colab.\n",
        "\n",
        "## After This Notebook You Can\n",
        "\n",
        "Reshape tensors without breaking meaning.\n",
        "Choose between view and reshape correctly.\n",
        "Add or remove dimensions safely.\n",
        "Reorder dimensions intentionally.\n",
        "Recall the right method quickly during debugging or interviews.\n",
        "\n",
        "## Out of Scope\n",
        "\n",
        "Broadcasting rules.\n",
        "Advanced indexing.\n",
        "Autograd internals.\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS COVERED (SUMMARY)\n",
        "\n",
        "Reshaping and structure:\n",
        "\n",
        "* tensor.reshape\n",
        "* tensor.view\n",
        "* tensor.flatten\n",
        "* tensor.squeeze\n",
        "* tensor.unsqueeze\n",
        "* tensor.permute\n",
        "* tensor.transpose\n",
        "* tensor.contiguous\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.reshape\n",
        "\n",
        "What it does:\n",
        "Changes the shape of a tensor while keeping the same data.\n",
        "\n",
        "When to use:\n",
        "Default choice when reshaping unless you explicitly need shared memory.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.arange(6)\n",
        "x.reshape(2, 3)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* new shape (tuple or positional arguments)\n",
        "\n",
        "Common mistake:\n",
        "Assuming it always returns a view (it may create a copy).\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.view\n",
        "\n",
        "What it does:\n",
        "Returns a new view of the same tensor with a different shape.\n",
        "\n",
        "When to use:\n",
        "When you want reshaping without allocating new memory.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.arange(6)\n",
        "x.view(2, 3)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* new shape\n",
        "\n",
        "Common mistake:\n",
        "Using view on non-contiguous tensors (will error).\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.flatten\n",
        "\n",
        "What it does:\n",
        "Flattens a tensor into a 1D tensor or partially flattens selected dimensions.\n",
        "\n",
        "When to use:\n",
        "Before feeding tensors into linear layers.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.randn(2, 3, 4)\n",
        "x.flatten()\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* start_dim\n",
        "* end_dim\n",
        "\n",
        "Common mistake:\n",
        "Flattening batch dimension unintentionally.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.squeeze\n",
        "\n",
        "What it does:\n",
        "Removes dimensions of size 1.\n",
        "\n",
        "When to use:\n",
        "Cleaning up tensors with unnecessary singleton dimensions.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.randn(1, 3, 1)\n",
        "x.squeeze()\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* dim (optional)\n",
        "\n",
        "Common mistake:\n",
        "Accidentally removing the batch dimension.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.unsqueeze\n",
        "\n",
        "What it does:\n",
        "Adds a dimension of size 1 at the specified position.\n",
        "\n",
        "When to use:\n",
        "Adding batch or channel dimensions.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "v = torch.tensor([1, 2, 3])\n",
        "v.unsqueeze(0)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* dim\n",
        "\n",
        "Common mistake:\n",
        "Adding dimension at the wrong index.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.permute\n",
        "\n",
        "What it does:\n",
        "Reorders the dimensions of a tensor.\n",
        "\n",
        "When to use:\n",
        "Changing data layout, such as channel-last to channel-first.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "img = torch.randn(3, 32, 32)\n",
        "img.permute(1, 2, 0)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* dimension order (tuple)\n",
        "\n",
        "Common mistake:\n",
        "Forgetting to update downstream code expectations.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.transpose\n",
        "\n",
        "What it does:\n",
        "Swaps two dimensions of a tensor.\n",
        "\n",
        "When to use:\n",
        "Simple dimension swaps, especially for matrices.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "m = torch.randn(2, 3)\n",
        "m.transpose(0, 1)\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* dim0\n",
        "* dim1\n",
        "\n",
        "Common mistake:\n",
        "Assuming transpose works for more than two dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.contiguous\n",
        "\n",
        "What it does:\n",
        "Returns a contiguous tensor in memory.\n",
        "\n",
        "When to use:\n",
        "Before calling view on a permuted or transposed tensor.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.randn(2, 3)\n",
        "y = x.transpose(0, 1)\n",
        "y.is_contiguous(), y.contiguous().is_contiguous()\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "None\n",
        "\n",
        "Common mistake:\n",
        "Using contiguous without understanding why it is needed.\n",
        "\n",
        "---\n",
        "\n",
        "## HANDS-ON PRACTICE\n",
        "\n",
        "1. Create a tensor of shape (2, 3, 4) and flatten only the last two dimensions.\n",
        "2. Add and then remove a batch dimension safely.\n",
        "3. Permute an image tensor from (C, H, W) to (H, W, C).\n",
        "4. Try using view on a transposed tensor and fix it using contiguous().\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS RECAP (ONE PLACE)\n",
        "\n",
        "reshape, view, flatten, squeeze, unsqueeze, permute, transpose, contiguous\n",
        "\n",
        "---\n",
        "\n",
        "## ONE-SENTENCE SUMMARY\n",
        "\n",
        "Shape methods change structure, not data, and must respect meaning and memory.\n",
        "\n",
        "---\n",
        "\n",
        "## WHERE THIS FITS NEXT\n",
        "\n",
        "Next reference notebook:\n",
        "PyTorch_Methods_03 â€” Tensor Math & Reduction Methods\n"
      ],
      "metadata": {
        "id": "2z2u42dmrocC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CCCrIHx8sEhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54e81d70"
      },
      "source": [
        "### `tensor.reshape` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f734989",
        "outputId": "b45887e6-7c10-4562-a169-4c48fdc54484"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(6)\n",
        "reshaped_x = x.reshape(2, 3)\n",
        "print(\"Original tensor:\", x)\n",
        "print(\"Reshaped tensor:\", reshaped_x)\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"Reshaped shape:\", reshaped_x.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor: tensor([0, 1, 2, 3, 4, 5])\n",
            "Reshaped tensor: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Original shape: torch.Size([6])\n",
            "Reshaped shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ba6571"
      },
      "source": [
        "### `tensor.view` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04ede70",
        "outputId": "667f54d2-6660-4c03-a3d0-41690d10b222"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(6)\n",
        "viewed_x = x.view(2, 3)\n",
        "print(\"Original tensor:\", x)\n",
        "print(\"Viewed tensor:\", viewed_x)\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"Viewed shape:\", viewed_x.shape)\n",
        "# Check if memory is shared\n",
        "x[0] = 99\n",
        "print(\"Modified original tensor:\", x)\n",
        "print(\"View after original modified:\", viewed_x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor: tensor([0, 1, 2, 3, 4, 5])\n",
            "Viewed tensor: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Original shape: torch.Size([6])\n",
            "Viewed shape: torch.Size([2, 3])\n",
            "Modified original tensor: tensor([99,  1,  2,  3,  4,  5])\n",
            "View after original modified: tensor([[99,  1,  2],\n",
            "        [ 3,  4,  5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dc50bfa"
      },
      "source": [
        "### `tensor.flatten` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b519df7",
        "outputId": "0b81eee5-2c8a-4daa-d4be-e56cccf85e7b"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(2, 3, 4)\n",
        "flattened_x = x.flatten()\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "print(\"Flattened tensor shape:\", flattened_x.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([2, 3, 4])\n",
            "Flattened tensor shape: torch.Size([24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44e189da"
      },
      "source": [
        "### `tensor.squeeze` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c2fa3d1",
        "outputId": "3eb2aa0f-c67d-4fa1-df13-842d9c21b90a"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(1, 3, 1)\n",
        "squeezed_x = x.squeeze()\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "print(\"Squeezed tensor shape:\", squeezed_x.shape)\n",
        "\n",
        "y = torch.randn(1, 5, 1, 2)\n",
        "squeezed_dim_y = y.squeeze(dim=2)\n",
        "print(\"\\nOriginal tensor y shape:\", y.shape)\n",
        "print(\"Squeezed dim 2 of y shape:\", squeezed_dim_y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([1, 3, 1])\n",
            "Squeezed tensor shape: torch.Size([3])\n",
            "\n",
            "Original tensor y shape: torch.Size([1, 5, 1, 2])\n",
            "Squeezed dim 2 of y shape: torch.Size([1, 5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bb48fae"
      },
      "source": [
        "### `tensor.unsqueeze` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4db2d0",
        "outputId": "88dfbd28-7e4a-4cb0-82f0-df1773a7cb32"
      },
      "source": [
        "import torch\n",
        "\n",
        "v = torch.tensor([1, 2, 3])\n",
        "unsqueezed_v = v.unsqueeze(0)\n",
        "print(\"Original tensor shape:\", v.shape)\n",
        "print(\"Unsqueezed tensor shape (dim 0):\", unsqueezed_v.shape)\n",
        "\n",
        "unsqueezed_v_dim1 = v.unsqueeze(1)\n",
        "print(\"Unsqueezed tensor shape (dim 1):\", unsqueezed_v_dim1.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([3])\n",
            "Unsqueezed tensor shape (dim 0): torch.Size([1, 3])\n",
            "Unsqueezed tensor shape (dim 1): torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112f8ef8"
      },
      "source": [
        "### `tensor.permute` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd3ef7cb",
        "outputId": "528a3dec-11f3-49e1-94e6-f5f23dba5f1e"
      },
      "source": [
        "import torch\n",
        "\n",
        "img = torch.randn(3, 32, 32) # C, H, W\n",
        "permuted_img = img.permute(1, 2, 0) # H, W, C\n",
        "print(\"Original image shape (C, H, W):\", img.shape)\n",
        "print(\"Permuted image shape (H, W, C):\", permuted_img.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image shape (C, H, W): torch.Size([3, 32, 32])\n",
            "Permuted image shape (H, W, C): torch.Size([32, 32, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c46876b"
      },
      "source": [
        "### `tensor.transpose` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7e43d16",
        "outputId": "a1a296ea-57b8-4573-82f7-78b11286cf0e"
      },
      "source": [
        "import torch\n",
        "\n",
        "m = torch.randn(2, 3)\n",
        "transposed_m = m.transpose(0, 1)\n",
        "print(\"Original matrix shape:\", m.shape)\n",
        "print(\"Transposed matrix shape:\", transposed_m.shape)\n",
        "print(\"\\nOriginal matrix:\\n\", m)\n",
        "print(\"\\nTransposed matrix:\\n\", transposed_m)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix shape: torch.Size([2, 3])\n",
            "Transposed matrix shape: torch.Size([3, 2])\n",
            "\n",
            "Original matrix:\n",
            " tensor([[-0.1433, -0.5129,  0.6119],\n",
            "        [-0.3081, -1.5291, -0.5405]])\n",
            "\n",
            "Transposed matrix:\n",
            " tensor([[-0.1433, -0.3081],\n",
            "        [-0.5129, -1.5291],\n",
            "        [ 0.6119, -0.5405]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3cb933f"
      },
      "source": [
        "### `tensor.contiguous` example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26fb76c8",
        "outputId": "3eac74c7-361e-4ff4-db9e-4c0bcfdebff1"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(2, 3)\n",
        "y = x.transpose(0, 1)\n",
        "print(\"Original tensor x is contiguous:\", x.is_contiguous())\n",
        "print(\"Transposed tensor y is contiguous:\", y.is_contiguous())\n",
        "\n",
        "y_contiguous = y.contiguous()\n",
        "print(\"y.contiguous() is contiguous:\", y_contiguous.is_contiguous())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor x is contiguous: True\n",
            "Transposed tensor y is contiguous: False\n",
            "y.contiguous() is contiguous: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41faf938"
      },
      "source": [
        "## Solutions to HANDS-ON PRACTICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "793650aa"
      },
      "source": [
        "### 1. Create a tensor of shape (2, 3, 4) and flatten only the last two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7710347",
        "outputId": "2aa71fdb-4cd3-41aa-f268-3ef6f9c728b5"
      },
      "source": [
        "import torch\n",
        "\n",
        "tensor_3d = torch.arange(2 * 3 * 4).reshape(2, 3, 4)\n",
        "print(\"Original tensor:\\n\", tensor_3d)\n",
        "print(\"Original shape:\", tensor_3d.shape)\n",
        "\n",
        "# Flatten only the last two dimensions (from dim 1 to dim 2)\n",
        "flattened_last_two_dims = tensor_3d.flatten(start_dim=1)\n",
        "print(\"\\nTensor after flattening last two dimensions:\\n\", flattened_last_two_dims)\n",
        "print(\"Shape after flattening last two dimensions:\", flattened_last_two_dims.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "Original shape: torch.Size([2, 3, 4])\n",
            "\n",
            "Tensor after flattening last two dimensions:\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
            "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])\n",
            "Shape after flattening last two dimensions: torch.Size([2, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96305c9"
      },
      "source": [
        "### 2. Add and then remove a batch dimension safely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f2f3042",
        "outputId": "43b92c4f-296a-4d83-99f1-d221bea93b42"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3, 5) # Example tensor\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "\n",
        "# Add a batch dimension at the beginning (dim 0)\n",
        "x_with_batch = x.unsqueeze(0)\n",
        "print(\"Shape after adding batch dimension:\", x_with_batch.shape)\n",
        "\n",
        "# Remove the batch dimension\n",
        "x_without_batch = x_with_batch.squeeze(0)\n",
        "print(\"Shape after removing batch dimension:\", x_without_batch.shape)\n",
        "\n",
        "# Verify original shape is restored\n",
        "print(\"Original shape restored:\", x.shape == x_without_batch.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([3, 5])\n",
            "Shape after adding batch dimension: torch.Size([1, 3, 5])\n",
            "Shape after removing batch dimension: torch.Size([3, 5])\n",
            "Original shape restored: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ce370e"
      },
      "source": [
        "### 3. Permute an image tensor from (C, H, W) to (H, W, C)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d9bbb82",
        "outputId": "395c34e2-24d3-4fa5-ccce-339b762e211e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Simulate an image tensor (Channels, Height, Width)\n",
        "image_chw = torch.randn(3, 64, 128) # 3 channels, 64 height, 128 width\n",
        "print(\"Original image shape (C, H, W):\", image_chw.shape)\n",
        "\n",
        "# Permute to (H, W, C)\n",
        "image_hwc = image_chw.permute(1, 2, 0)\n",
        "print(\"Permuted image shape (H, W, C):\", image_hwc.shape)\n",
        "\n",
        "# You can also permute back\n",
        "image_chw_back = image_hwc.permute(2, 0, 1)\n",
        "print(\"Permuted back to (C, H, W) shape:\", image_chw_back.shape)\n",
        "print(\"Original tensor equals permuted back tensor:\", torch.equal(image_chw, image_chw_back))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image shape (C, H, W): torch.Size([3, 64, 128])\n",
            "Permuted image shape (H, W, C): torch.Size([64, 128, 3])\n",
            "Permuted back to (C, H, W) shape: torch.Size([3, 64, 128])\n",
            "Original tensor equals permuted back tensor: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce27b9b6"
      },
      "source": [
        "### 4. Try using view on a transposed tensor and fix it using `contiguous()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdbe5644",
        "outputId": "e368dcab-ed79-4b47-cb72-1567c5d4a0c6"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(6).reshape(2, 3)\n",
        "print(\"Original tensor x:\\n\", x)\n",
        "\n",
        "# Transpose the tensor\n",
        "y = x.transpose(0, 1)\n",
        "print(\"\\nTransposed tensor y:\\n\", y)\n",
        "print(\"y is contiguous:\", y.is_contiguous())\n",
        "\n",
        "# Trying to use view on a non-contiguous tensor will raise a RuntimeError\n",
        "try:\n",
        "    y.view(3, 2)\n",
        "except RuntimeError as e:\n",
        "    print(f\"\\nError when calling view on non-contiguous tensor: {e}\")\n",
        "\n",
        "# Fix it by making it contiguous first\n",
        "y_contiguous = y.contiguous()\n",
        "print(\"\\ny_contiguous is contiguous:\", y_contiguous.is_contiguous())\n",
        "\n",
        "# Now view works\n",
        "viewed_y_fixed = y_contiguous.view(3, 2)\n",
        "print(\"\\nViewed tensor after making it contiguous:\\n\", viewed_y_fixed)\n",
        "print(\"Shape of viewed_y_fixed:\", viewed_y_fixed.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor x:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "\n",
            "Transposed tensor y:\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "y is contiguous: False\n",
            "\n",
            "y_contiguous is contiguous: True\n",
            "\n",
            "Viewed tensor after making it contiguous:\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "Shape of viewed_y_fixed: torch.Size([3, 2])\n"
          ]
        }
      ]
    }
  ]
}