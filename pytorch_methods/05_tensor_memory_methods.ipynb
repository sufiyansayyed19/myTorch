{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLDZj/dmvNJPt5m0HO0sZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/myTorch/blob/main/05_tensor_memory_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Goal\n",
        "\n",
        "Provide a focused, example-driven reference for PyTorch tensor memory, copying, and mutation methods so side effects are predictable and safe.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Level 1 completed.\n",
        "Basic understanding of tensor references and reshaping.\n",
        "\n",
        "## After This Notebook You Can\n",
        "\n",
        "Decide when tensors share memory or own copies.\n",
        "Use clone() and detach() correctly.\n",
        "Identify and control in-place operations.\n",
        "Explain memory-related methods in interviews.\n",
        "\n",
        "## Out of Scope\n",
        "\n",
        "Autograd graph internals.\n",
        "Performance micro-optimizations.\n",
        "Distributed training.\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS COVERED (SUMMARY)\n",
        "\n",
        "Memory & mutation:\n",
        "\n",
        "* clone\n",
        "* detach\n",
        "* requires_grad_\n",
        "* copy_\n",
        "* is_contiguous\n",
        "* In-place ops (_)\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.clone\n",
        "\n",
        "What it does:\n",
        "Creates a new tensor with its own memory, copying values from the source.\n",
        "\n",
        "When to use:\n",
        "When you need an independent copy before mutation.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = x.clone()\n",
        "\n",
        "y[0] = 99\n",
        "x, y\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "None\n",
        "\n",
        "Common mistake:\n",
        "Assuming assignment (y = x) makes a copy.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.detach\n",
        "\n",
        "What it does:\n",
        "Returns a tensor that shares memory but is detached from gradient tracking.\n",
        "\n",
        "When to use:\n",
        "Before converting to NumPy or when stopping gradients intentionally.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x.detach()\n",
        "\n",
        "y.requires_grad\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "None\n",
        "\n",
        "Common mistake:\n",
        "Thinking detach() copies data (it does not).\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.requires_grad_\n",
        "\n",
        "What it does:\n",
        "Enables or disables gradient tracking in-place.\n",
        "\n",
        "When to use:\n",
        "Freezing or unfreezing tensors for training.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "x.requires_grad_(True)\n",
        "x.requires_grad\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* flag (True or False)\n",
        "\n",
        "Common mistake:\n",
        "Using it on non-leaf tensors without understanding consequences.\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.copy_\n",
        "\n",
        "What it does:\n",
        "Copies values from another tensor into this tensor in-place.\n",
        "\n",
        "When to use:\n",
        "Updating buffers without reallocating memory.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.zeros(3)\n",
        "y = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "x.copy_(y)\n",
        "x\n",
        "```\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "* source tensor\n",
        "\n",
        "Common mistake:\n",
        "Assuming it returns a new tensor (it modifies in-place).\n",
        "\n",
        "---\n",
        "\n",
        "## tensor.is_contiguous\n",
        "\n",
        "What it does:\n",
        "Checks whether tensor memory is contiguous.\n",
        "\n",
        "When to use:\n",
        "Before calling view() or performance-sensitive ops.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.randn(2, 3)\n",
        "y = x.transpose(0, 1)\n",
        "\n",
        "y.is_contiguous(), y.contiguous().is_contiguous()\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Ignoring contiguity when using view().\n",
        "\n",
        "---\n",
        "\n",
        "## In-Place Operations (_)\n",
        "\n",
        "What they do:\n",
        "Modify tensor values directly in memory.\n",
        "\n",
        "When to use:\n",
        "Carefully, when you are sure no other references depend on the data.\n",
        "\n",
        "Minimal example:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "x.add_(10)\n",
        "x\n",
        "```\n",
        "\n",
        "Common mistake:\n",
        "Breaking gradient computation or mutating shared tensors.\n",
        "\n",
        "---\n",
        "\n",
        "## HANDS-ON PRACTICE\n",
        "\n",
        "1. Assign one tensor to another and demonstrate shared memory.\n",
        "2. Use clone() to prevent side effects.\n",
        "3. Detach a tensor with requires_grad=True and convert it to NumPy.\n",
        "4. Use an in-place op and rewrite it as a non in-place alternative.\n",
        "5. Check contiguity before and after transpose.\n",
        "\n",
        "---\n",
        "\n",
        "## METHODS RECAP (ONE PLACE)\n",
        "\n",
        "clone, detach, requires_grad_, copy_, is_contiguous, in-place ops (_)\n",
        "\n",
        "---\n",
        "\n",
        "## ONE-SENTENCE SUMMARY\n",
        "\n",
        "Most silent bugs come from shared memory and in-place mutation.\n",
        "\n",
        "---\n",
        "\n",
        "## WHERE THIS FITS NEXT\n",
        "\n",
        "Next reference notebook:\n",
        "PyTorch_Methods_06 â€” Tensor Device & Type Utilities\n"
      ],
      "metadata": {
        "id": "fdZB-9WK8oYV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17fa7ede",
        "outputId": "21ddfb00-b7da-48fb-ec9b-21f572a0a7bc"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"tensor.clone example:\")\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = x.clone()\n",
        "\n",
        "y[0] = 99\n",
        "print(f\"Original tensor x: {x}\")\n",
        "print(f\"Cloned tensor y (modified): {y}\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.clone example:\n",
            "Original tensor x: tensor([1., 2., 3.])\n",
            "Cloned tensor y (modified): tensor([99.,  2.,  3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22a6a78d",
        "outputId": "a6ab9d73-cea2-496e-9afe-8e26fa8185f1"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"tensor.detach example:\")\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x.detach()\n",
        "\n",
        "print(f\"Original tensor x requires_grad: {x.requires_grad}\")\n",
        "print(f\"Detached tensor y requires_grad: {y.requires_grad}\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.detach example:\n",
            "Original tensor x requires_grad: True\n",
            "Detached tensor y requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c910f1dd",
        "outputId": "0097a95a-bc29-4b5b-b052-2d7e98d2bed9"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"tensor.requires_grad_ example:\")\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Tensor x initially requires_grad: {x.requires_grad}\")\n",
        "x.requires_grad_(True)\n",
        "print(f\"Tensor x after requires_grad_(True): {x.requires_grad}\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.requires_grad_ example:\n",
            "Tensor x initially requires_grad: False\n",
            "Tensor x after requires_grad_(True): True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9bfb63d",
        "outputId": "2adbd04c-fcb1-44d4-8be7-6781d5a3cedd"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"tensor.copy_ example:\")\n",
        "x = torch.zeros(3)\n",
        "y = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "print(f\"Tensor x before copy_: {x}\")\n",
        "x.copy_(y)\n",
        "print(f\"Tensor x after copy_ from y: {x}\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.copy_ example:\n",
            "Tensor x before copy_: tensor([0., 0., 0.])\n",
            "Tensor x after copy_ from y: tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6152f0cf",
        "outputId": "e692152a-0b44-4b6f-d0bc-dcfe683d6e79"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"tensor.is_contiguous example:\")\n",
        "x = torch.randn(2, 3)\n",
        "y = x.transpose(0, 1)\n",
        "\n",
        "print(f\"Is x contiguous: {x.is_contiguous()}\")\n",
        "print(f\"Is y (transposed x) contiguous: {y.is_contiguous()}\")\n",
        "print(f\"Is contiguous version of y contiguous: {y.contiguous().is_contiguous()}\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.is_contiguous example:\n",
            "Is x contiguous: True\n",
            "Is y (transposed x) contiguous: False\n",
            "Is contiguous version of y contiguous: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "269a97eb",
        "outputId": "be711444-487c-49b8-e21d-53b1aea3d0d3"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"In-Place Operations (_) example:\")\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Tensor x before in-place add_: {x}\")\n",
        "x.add_(10) # In-place addition\n",
        "print(f\"Tensor x after in-place add_(10): {x}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-Place Operations (_) example:\n",
            "Tensor x before in-place add_: tensor([1., 2., 3.])\n",
            "Tensor x after in-place add_(10): tensor([11., 12., 13.])\n"
          ]
        }
      ]
    }
  ]
}